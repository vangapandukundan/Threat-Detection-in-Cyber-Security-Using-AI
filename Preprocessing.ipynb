{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e56986",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.utils import resample\n",
    "from sklearn import preprocessing\n",
    "from warnings import simplefilter\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Suppress FutureWarning messages\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Record start time\n",
    "start_time = time.time()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9356f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV files names:\n",
    "all_files = [\n",
    "    \"Tuesday-WorkingHours.pcap_ISCX\",\n",
    "    \"Wednesday-workingHours.pcap_ISCX\",\n",
    "    \"Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX\",\n",
    "    \"Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX\",\n",
    "    \"Friday-WorkingHours-Morning.pcap_ISCX\",\n",
    "    \"Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX\",\n",
    "    \"Friday-WorkingHours-Afternoon-DDos.pcap_ISCX\"\n",
    "]\n",
    "'''\n",
    "# Load the first CSV file\n",
    "initial_df = pd.read_csv(\"Monday-WorkingHours.pcap_ISCX.csv\")\n",
    "initial_df.columns = initial_df.columns.str.strip()\n",
    "main_labels = repr(list(initial_df.columns)) + \"\\n\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48ed2492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing and undersampling of file Tuesday-WorkingHours.pcap_ISCX  is done\n",
      "Preprocessing and undersampling of file Wednesday-workingHours.pcap_ISCX  is done\n",
      "Preprocessing and undersampling of file Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX  is done\n",
      "Preprocessing and undersampling of file Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX  is done\n",
      "Preprocessing and undersampling of file Friday-WorkingHours-Morning.pcap_ISCX  is done\n",
      "Preprocessing and undersampling of file Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX  is done\n",
      "Preprocessing and undersampling of file Friday-WorkingHours-Afternoon-DDos.pcap_ISCX  is done\n",
      "Concatenation and saving to CSV is done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize a list to store processed DataFrames\n",
    "processed_dataframes = []\n",
    "\n",
    "# Create a StandardScaler instance for normalization\n",
    "std_scaler = StandardScaler()\n",
    "\n",
    "# Function for normalization\n",
    "def normalize_dataframe(df, columns_to_normalize):\n",
    "    df[columns_to_normalize] = std_scaler.fit_transform(df[columns_to_normalize])\n",
    "    return df\n",
    "\n",
    "for file_path in all_files:\n",
    "    # Read CSV file\n",
    "    df = pd.read_csv(file_path + \".csv\", encoding='iso-8859-2', engine='python')\n",
    "    df = pd.DataFrame(df)\n",
    "    \n",
    "    # Drop rows with missing Flow Duration values\n",
    "    df = df.drop(df[pd.isnull(df[\" Flow Duration\"])].index)\n",
    "    \n",
    "    # Replace infinite values with NaN\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    \n",
    "    # Drop rows with NaN values\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    # Normalize numeric columns\n",
    "    numeric_columns = df.select_dtypes(include='number').columns\n",
    "    df[numeric_columns] = df[numeric_columns].astype(np.float32)\n",
    "    df = normalize_dataframe(df.copy(), numeric_columns)\n",
    "    \n",
    "    # Identify and handle categorical columns\n",
    "    string_columns = [col for col in df.columns if df[col].dtype == \"object\"]\n",
    "    try:\n",
    "        string_columns.remove(' Label')\n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "    # Convert categorical columns to numeric\n",
    "    label_encoder_X = preprocessing.LabelEncoder()\n",
    "    for col in string_columns:\n",
    "        try:\n",
    "            df[col] = label_encoder_X.fit_transform(df[col])\n",
    "        except:\n",
    "            df[col] = df[col].replace('Infinity', -1)\n",
    "   \n",
    "        # Append the processed and undersampled DataFrame to the list\n",
    "    processed_dataframes.append(df)\n",
    "    print(\"Preprocessing and undersampling of file\", file_path, \" is done\")\n",
    "# Concatenate the processed DataFrames\n",
    "combined_dataframe = pd.concat(processed_dataframes, ignore_index=True)\n",
    "\n",
    "# Save the concatenated DataFrame to a new CSV file\n",
    "combined_dataframe.to_csv(\"combined_data.csv\", index=False)\n",
    "print(\"Concatenation and saving to CSV is done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca786f11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
